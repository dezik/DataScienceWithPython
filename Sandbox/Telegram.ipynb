{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37664bitdatasciencecondae8f42ab0efea4f998c891fa6287f9d0d",
   "display_name": "Python 3.7.6 64-bit ('datascience': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Read chat to DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_json('../Data/dva_dimona_vovonjaka.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "allChats = json_normalize(data.chats[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = json_normalize(allChats.messages[0])\n",
    "chat.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = chat[chat['type']=='message']\n",
    "chat = chat[['id', 'date', 'edited', 'text', 'from', 'media_type', 'sticker_emoji', 'reply_to_message_id']]\n",
    "chat['date'] = chat['date'].apply(lambda x: pd.Timestamp(x))\n",
    "chat['edited'] = chat['edited'].apply(lambda x: pd.Timestamp(x))\n",
    "chat.replace(pd.Timestamp('1970-01-01T01:00:00'), pd.NA, inplace=True)\n",
    "chat.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Statistics about message types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols=4, figsize = (12,4))\n",
    "plt.subplots_adjust(wspace=0.5, hspace=0.5)\n",
    "\n",
    "chat['from'].value_counts().plot(kind='bar', title='Количество сообщений', ax=axes[0])\n",
    "chat[chat.media_type == 'sticker']['from'].value_counts().plot(kind='bar', title='Количество стикеров', ax=axes[1])\n",
    "chat[chat.text.apply(lambda x: not isinstance(x, str))]['from'].value_counts().plot(kind='bar', title='Количество ссылок', ax=axes[2])\n",
    "chat[chat.media_type == 'video_file']['from'].value_counts().plot(kind='bar', title='Количество видео', ax=axes[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Extract data from non-text messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msgs = np.array([])\n",
    "mentions = np.array([])\n",
    "links = np.array([])\n",
    "for l in chat[chat.text.apply(lambda x: isinstance(x, list))].text.values:\n",
    "    for item in l:\n",
    "        if isinstance(item, str):\n",
    "            msgs = np.append(item, msgs)\n",
    "        if isinstance(item, dict):\n",
    "            if item['type'] == 'link':\n",
    "                links = np.append(item['text'], links)\n",
    "            if item['type'] == 'mention':\n",
    "                mentions = np.append(item['text'], mentions)\n",
    "                # mentions.append(item['text'])\n",
    "\n",
    "print('Messages: ', msgs)\n",
    "print()\n",
    "print('Mentions: ', mentions)\n",
    "print()\n",
    "print('Links: ', links)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define tokenixzation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from pymystem3 import Mystem\n",
    "from string import punctuation\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "mystem = Mystem() \n",
    "def tokenize(text:str, stopWords: []):\n",
    "    tokens = mystem.lemmatize(text.lower())\n",
    "    tokens = [i.replace(\"«\", \"\").replace(\"»\", \"\") for i in tokens]\n",
    "\n",
    "    for p in punctuation:\n",
    "        if p != '-':\n",
    "            tokens = [t.replace(p, \" \") for t in tokens]\n",
    "\n",
    "    return [token.strip() for token in tokens if token.strip() not in stopWords\\\n",
    "              and token.strip() != \"\" \\\n",
    "              and not token.isdigit()\n",
    "              and token.strip() >= 'А'\n",
    "              and token.strip() <='я'\n",
    "              and token.strip() not in punctuation]"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Define stop-words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = stopwords.words('russian')\n",
    "stop_words.extend(['что', 'это', 'так', 'вот', 'быть', 'как', 'в', '—', '–', 'к', 'на', '...', '✔', '•', '’', 'че', 'ток', 'шо', 'тип'])"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Difine function for getting user vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def getTextMessage(obj):\n",
    "    if isinstance(obj, str):\n",
    "        return obj\n",
    "    elif isinstance(obj, list):\n",
    "        text = ''\n",
    "        for item in obj:\n",
    "            if isinstance(item, str):\n",
    "                text += item.strip() + ' '\n",
    "        return text\n",
    "    else:\n",
    "        return pd.NA\n",
    "\n",
    "def getMessageChat(df):\n",
    "    messageChat = df[['text', 'from', 'date']]\n",
    "    messageChat.text = messageChat.text.apply(getTextMessage)\n",
    "    return messageChat\n",
    "\n",
    "def getTextMessages(data):\n",
    "    messages = data[data.apply(lambda x: isinstance(x, str))]\n",
    "    nonMessages = data[data.apply(lambda x: isinstance(x, list))]\n",
    "    msgs = []\n",
    "    for l in nonMessages.values:\n",
    "        for item in l:\n",
    "            if isinstance(item, str):\n",
    "                msgs.append(item)\n",
    "    return np.append(messages.values, msgs)\n",
    "\n",
    "def getSentences(data):\n",
    "    sentences = []\n",
    "    for msg in getTextMessages(data):\n",
    "        if msg >= 'А':\n",
    "            sentences.extend(map(lambda s: s.capitalize().strip() ,nltk.sent_tokenize(msg)))\n",
    "    return np.array(sentences)\n",
    "\n",
    "def getTokens(data, stopWords=[]):\n",
    "    return tokenize(' '.join(getTextMessages(data)), stopWords)\n",
    "\n",
    "def getTokensFrequency(data, stopWords=[]):\n",
    "    tokens = getTokens(data, stopWords)\n",
    "    return Counter(tokens)\n",
    "\n",
    "def getUserVocabulary(sender:str, stopWords=[]):\n",
    "    allMsgs = chat[chat['from'] == sender].text\n",
    "    tokens = getTokens(allMsgs, stopWords)\n",
    "    return Counter(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get user most used words statistic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols=3, figsize = (15,4))\n",
    "plt.subplots_adjust(wspace=0.5, hspace=0.5)\n",
    "\n",
    "z_words, z_counts = zip(*getUserVocabulary('Dez Dezsson').most_common(20))\n",
    "d_words, d_counts = zip(*getUserVocabulary('Дима Лацюга').most_common(20))\n",
    "v_words, w_counts = zip(*getUserVocabulary('Вова Свинухов').most_common(20))\n",
    "\n",
    "axes[0].set_title('Dez Dezsson')\n",
    "axes[0].barh(z_words, z_counts)\n",
    "\n",
    "axes[1].set_title('Дима Лацюга')\n",
    "axes[1].barh(d_words, d_counts)\n",
    "\n",
    "axes[2].set_title('Вова Свинухов')\n",
    "axes[2].barh(v_words, w_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols=3, figsize = (15,4))\n",
    "plt.subplots_adjust(wspace=0.5, hspace=0.5)\n",
    "\n",
    "z_words, z_counts = zip(*getUserVocabulary('Dez Dezsson', stop_words).most_common(20))\n",
    "d_words, d_counts = zip(*getUserVocabulary('Дима Лацюга', stop_words).most_common(20))\n",
    "v_words, w_counts = zip(*getUserVocabulary('Вова Свинухов', stop_words).most_common(20))\n",
    "\n",
    "axes[0].set_title('Dez Dezsson')\n",
    "axes[0].barh(z_words, z_counts)\n",
    "\n",
    "axes[1].set_title('Дима Лацюга')\n",
    "axes[1].barh(d_words, d_counts)\n",
    "\n",
    "axes[2].set_title('Вова Свинухов')\n",
    "axes[2].barh(v_words, w_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_len=len(getUserVocabulary('Dez Dezsson', stop_words).keys())\n",
    "d_len=len(getUserVocabulary('Дима Лацюга', stop_words).keys())\n",
    "v_len=len(getUserVocabulary('Вова Свинухов', stop_words).keys())\n",
    "plt.bar(['Dez Dezsson', 'Дима Лацюга', 'Вова Свинухов'], [z_len, d_len, v_len])\n",
    "plt.title(\"Словарный запас\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_count = len(chat[chat['from'] == 'Dez Dezsson'])\n",
    "d_count = len(chat[chat['from'] == 'Дима Лацюга'])\n",
    "v_count = len(chat[chat['from'] == 'Вова Свинухов'])\n",
    "\n",
    "print(z_count, d_count, v_count)\n",
    "\n",
    "plt.bar(['Dez Dezsson', 'Дима Лацюга', 'Вова Свинухов'], [z_len/z_count, d_len/d_count, v_len/v_count])\n",
    "plt.title(\"Словарный запас vs колличество сообщений\")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Find n-gramms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findNGramms(data, n=1, most_common=20, stop_words=[]):\n",
    "    tokens = getTokens(data, stop_words)\n",
    "    words=nltk.ngrams(tokens, n)\n",
    "    words=nltk.FreqDist(words)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### N-граммы Димона"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "findNGramms(chat[chat['from'] == 'Дима Лацюга'].text, n=2, stop_words=stop_words).plot(20, title = 'Дима Лацюга 2-gramms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "findNGramms(chat[chat['from'] == 'Дима Лацюга'].text, n=3, stop_words=stop_words).plot(20, title = 'Дима Лацюга 3-gramms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "findNGramms(chat[chat['from'] == 'Дима Лацюга'].text, n=4, stop_words=stop_words).plot(20, title = 'Дима Лацюга 4-gramms')"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### N-граммы Вовоняки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "findNGramms(chat[chat['from'] == 'Вова Свинухов'].text, n=2, stop_words=stop_words).plot(20, title = 'Вова Свинухов 2-gramms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "findNGramms(chat[chat['from'] == 'Вова Свинухов'].text, n=3, stop_words=stop_words).plot(20, title = 'Вова Свинухов 3-gramms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "findNGramms(chat[chat['from'] == 'Вова Свинухов'].text, n=4, stop_words=stop_words).plot(20, title = 'Вова Свинухов 4-gramms')"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Мои N-граммы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "findNGramms(chat[chat['from'] == 'Dez Dezsson'].text, n=2, stop_words=stop_words).plot(20, title = 'Dez Dezsson 2-gramms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "findNGramms(chat.text, n=2, stop_words=stop_words).plot(20, title = 'Наиболее частые 2-gramms')"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import markovify\n",
    "\n",
    "def generateText(data, n=10):\n",
    "    text = \". \".join(getSentences(data))\n",
    "    textModel = markovify.Text(text, state_size=3, well_formed = True)\n",
    "    text = ''\n",
    "    for i in range(n):\n",
    "        text += textModel.make_short_sentence(480, tries=100) + ' '\n",
    "    return text\n",
    "    \n",
    "generateText(chat.text, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## NaiveBayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "counts = vectorizer.fit_transform(train.text.values)\n",
    "\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(counts, train['from'].values)\n",
    "\n",
    "examples = ['Бля посоны', \"Павленский из той же тусовки, почитай про их перфомансы)\", \"Да и так вроде заебись, или бывает ошибается?\", \"если нет юзер специфик слов, то обычно выдает Димона, потому шо у него тупо сообщений больше\"]\n",
    "example_counts = vectorizer.transform(examples)\n",
    "predictions = classifier.predict(example_counts)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def predictSender(train_df, msgs:list):\n",
    "    cv = CountVectorizer()\n",
    "    clsf = MultinomialNB()\n",
    "    \n",
    "    message_counts = cv.fit_transform(train_df.text.values)\n",
    "    clsf.fit(message_counts, train_df['from'].values)\n",
    "    pr = clsf.predict(cv.transform(msgs))\n",
    "    return  pd.DataFrame({'text': msgs, 'from': pr})\n",
    "\n",
    "def get_test_results(train_df, test_df):\n",
    "    prediction = predictSender(train_df, test_df.text)\n",
    "    messages, real, predicted = [], [], []\n",
    "    for index, row in test_df.iterrows():\n",
    "        p, r = prediction['from'][index], row['from']\n",
    "        if r != p:\n",
    "            messages.append(row['text'])\n",
    "            real.append(r)\n",
    "            predicted.append(p)\n",
    "    return pd.DataFrame({'text': messages, 'real': real, 'predicted': predicted})\n",
    "\n",
    "chat = getMessageChat(chat)\n",
    "train, test = train_test_split(chat, test_size=0.2)\n",
    "p = get_test_results(train, test)\n",
    "\n",
    "print(f\"Truth coefficient is: {len(p)/len(test):.4f}\")\n",
    "p[p.predicted != 'Дима Лацюга'].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = ['Бля посоны', \"Павленский из той же тусовки, почитай про их перфомансы)\", \"Да и так вроде заебись, или бывает ошибается?\", \"если нет юзер специфик слов, то обычно выдает Димона, потому шо у него тупо сообщений больше\"]\n",
    "example_counts = vectorizer.transform(examples)\n",
    "predictions = classifier.predict(example_counts)\n",
    "predictions"
   ]
  }
 ]
}